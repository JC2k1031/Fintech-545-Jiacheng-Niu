{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "540b87d8-6eac-4da5-b638-3fc77732cec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date       SPY      AAPL      MSFT      AMZN      TSLA     GOOGL  \\\n",
      "1  2/15/2022 0:00  0.016127  0.023152  0.018542  0.008658  0.053291  0.007987   \n",
      "2  2/16/2022 0:00  0.001121 -0.001389 -0.001167  0.010159  0.001041  0.008268   \n",
      "3  2/17/2022 0:00 -0.021361 -0.021269 -0.029282 -0.021809 -0.050943 -0.037746   \n",
      "4  2/18/2022 0:00 -0.006475 -0.009356 -0.009631 -0.013262 -0.022103 -0.016116   \n",
      "5  2/22/2022 0:00 -0.010732 -0.017812 -0.000729 -0.015753 -0.041366 -0.004521   \n",
      "\n",
      "       GOOG      META      NVDA  ...       PNC      MDLZ        MO       ADI  \\\n",
      "1  0.008319  0.015158  0.091812  ...  0.012807 -0.004082  0.004592  0.052344   \n",
      "2  0.007784 -0.020181  0.000604  ...  0.006757 -0.002429  0.005763  0.038879   \n",
      "3 -0.037669 -0.040778 -0.075591  ... -0.034949  0.005326  0.015017 -0.046988   \n",
      "4 -0.013914 -0.007462 -0.035296  ... -0.000646 -0.000908  0.007203 -0.000436   \n",
      "5 -0.008163 -0.019790 -0.010659  ...  0.009494  0.007121 -0.008891  0.003243   \n",
      "\n",
      "       GILD       LMT       SYK        GM       TFC       TJX  \n",
      "1  0.003600 -0.012275  0.033021  0.026240  0.028572  0.013237  \n",
      "2  0.009294  0.012244  0.003363  0.015301 -0.001389 -0.025984  \n",
      "3 -0.009855  0.004833 -0.030857 -0.031925 -0.033380 -0.028763  \n",
      "4 -0.003916 -0.005942 -0.013674 -0.004506 -0.003677  0.015038  \n",
      "5 -0.001147 -0.000673  0.008342 -0.037654 -0.002246 -0.013605  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1663/4141197605.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[vars[i]] = p2[:,i]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = pd.read_csv(\"DailyPrices.csv\")\n",
    "\n",
    "# Calculate arithmetic returns for all prices\n",
    "returns = return_calculate(df, method=\"DISCRETE\", dateColumn=\"Date\")\n",
    "\n",
    "# Print the first few rows of the returns DataFrame\n",
    "print(returns.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec5cd31e-5ca4-4c29-a6ba-6c5ae08604a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         META\n",
      "1    0.017826\n",
      "2   -0.017513\n",
      "3   -0.038110\n",
      "4   -0.004795\n",
      "5   -0.017123\n",
      "..        ...\n",
      "184  0.067983\n",
      "185  0.000083\n",
      "186  0.054497\n",
      "187  0.105161\n",
      "188  0.012948\n",
      "\n",
      "[188 rows x 1 columns]\n",
      "Centered META mean: META    9.227253e-19\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the mean of the META returns series\n",
    "meta_mean = np.mean(modeling_meta_returns)\n",
    "\n",
    "# Subtract the mean from the META returns series\n",
    "modeling_meta_returns_centered = modeling_meta_returns - meta_mean\n",
    "\n",
    "print(modeling_meta_returns_centered)\n",
    "\n",
    "# Print the mean of the centered META returns series\n",
    "print(f\"Centered META mean: {np.mean(modeling_meta_returns_centered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b1c01fe-eead-43ff-b580-e4ff481cf7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06534605]\n"
     ]
    }
   ],
   "source": [
    "#Using a normal distribution.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "sd = np.std(modeling_meta_returns_centered)\n",
    "\n",
    "# Calculate the VaR at the 5% and 1% confidence levels\n",
    "VaR_05 = -norm.ppf(0.05, 0, sd)\n",
    "VaR_01 = -norm.ppf(0.01, 0, sd)\n",
    "\n",
    "print(VaR_05)\n",
    "#print(VaR_01)\n",
    "# Print the results\n",
    "#print(f\"VaR using a normal distribution (5% confidence level): {VaR_05:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48f88dd8-128e-4b31-94a0-1812befbdb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09669898426573666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_var(data, mean=0, alpha=0.05):\n",
    "  return mean - np.quantile(data, alpha)\n",
    "\n",
    "def calculate_exponential_weights(lags, l):\n",
    "  weights = []\n",
    "  for i in range(1, lags + 1):\n",
    "    weight = (1 - l) * l ** (i - 1)\n",
    "    weights.append(weight)\n",
    "  weights = np.array(weights)\n",
    "  weights = np.flip(weights)\n",
    "  normalized_weights = weights / weights.sum()\n",
    "  return normalized_weights\n",
    "\n",
    "def calculate_ewcov(data, l):\n",
    "  w = calculate_exponential_weights(data.shape[1], l)\n",
    "  error_matrix = data - data.mean(axis=1)\n",
    "  ewcov = error_matrix @ np.diag(w) @ error_matrix.T\n",
    "  return ewcov\n",
    "\n",
    "\n",
    "ew_cov = calculate_ewcov(np.matrix(modeling_meta_returns_centered).T, 0.94)\n",
    "ew_variance = ew_cov[0, 0]\n",
    "sigma = np.sqrt(ew_variance)\n",
    "simulation_ew = np.random.normal(0, sigma, 10000)\n",
    "var_ew = calculate_var(simulation_ew)\n",
    "print(var_ew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52773c-9a9c-4bee-84ea-10e638f4394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34080796-0023-4537-be4b-9708ab8e7919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR at 95% confidence level using an MLE model: -0.059015163290606514\n"
     ]
    }
   ],
   "source": [
    "#Using a MLE fitted T distribution.\n",
    "\n",
    "from scipy.stats import t\n",
    "\n",
    "# Fit a T distribution to the daily returns\n",
    "params = t.fit(modeling_meta_returns_centered)\n",
    "\n",
    "# Set the confidence level\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Calculate the VaR at the given confidence level\n",
    "var = t.ppf(1 - confidence_level, *params[:-2], loc=params[-2], scale=params[-1])\n",
    "\n",
    "print(\"VaR at 95% confidence level using an MLE model:\",var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01f79079-4b84-43fb-a8fe-b9ae289edd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR at 95% confidence level using an AR(1) model:  -0.06551931823069516\n"
     ]
    }
   ],
   "source": [
    "#Using a fitted AR(1) model.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# Fit an AR(1) model to the log returns\n",
    "model = sm.tsa.ARIMA(modeling_meta_returns_centered, order=(1,0,0))\n",
    "results = model.fit()\n",
    "\n",
    "# Calculate the standard deviation of the residuals\n",
    "sigma = np.sqrt(results.resid.var())\n",
    "\n",
    "# Set the confidence level and calculate the z-score\n",
    "alpha = 0.05\n",
    "z_alpha = norm.ppf(1-alpha)\n",
    "\n",
    "# Calculate the VaR\n",
    "VaR = - z_alpha * sigma \n",
    "\n",
    "print(\"VaR at 95% confidence level using an AR(1) model: \", VaR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd393277-686d-40f9-a9d2-bb1a1de5a3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR at 95% confidence level using historic simulation:  -0.05684504307257836\n"
     ]
    }
   ],
   "source": [
    "#Using a Historic Simulation.\n",
    "\n",
    "# Set the current value of the asset\n",
    "S = 100\n",
    "\n",
    "# Sort the returns in descending order\n",
    "sorted_returns = sorted(modeling_meta_returns_centered['META'].dropna(), reverse=True)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate the index at which the VaR cutoff occurs\n",
    "n = len(sorted_returns)\n",
    "cutoff_index = int(np.floor(n * alpha))\n",
    "\n",
    "# Calculate the VaR\n",
    "\n",
    "VaR = - sorted_returns[cutoff_index]\n",
    "\n",
    "print(\"VaR at 95% confidence level using historic simulation: \", VaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16a088-8fdd-40a0-85e8-f4d874dbd7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf6259-1fff-4fbb-a993-608fd85293a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53684f-c5aa-4b34-8dcc-a80517f32ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842e3ac-48ff-472a-85c8-2151463a559f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
